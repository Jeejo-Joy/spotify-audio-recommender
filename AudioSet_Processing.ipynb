{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective** Read the AudioSet data and convert it into a usable JSON format file.\n",
    "\n",
    "**Prerequisite**: \n",
    "1. Download the data from [AudioSet](https://research.google.com/audioset/download.html) and uncompress the `tar.gz` file. Make sure this notebook is in the same directory as the uncompressed embeddings folder that is generated `audioset_v1_embeddings`\n",
    "\n",
    "2. Download the class labels file from [class_labels_indices.csv](http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv) and keep it in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"audioset_v1_embeddings/eval\"\n",
    "class_labels_file = 'class_labels_indices.csv'\n",
    "dataset = []\n",
    "for file_name in os.listdir(directory):\n",
    "     if file_name.endswith(\".tfrecord\"):\n",
    "            dataset.append(os.path.join(directory,file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = pd.read_csv(class_labels_file)\n",
    "labels = class_labels['display_name'].tolist()\n",
    "\n",
    "music_class = class_labels[class_labels['display_name'].str.contains('Music', case=False)]\n",
    "music_labels = music_class['index'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index        mid                   display_name\n",
      "0      0   /m/09x0r                         Speech\n",
      "1      1  /m/05zppz      Male speech, man speaking\n",
      "2      2   /m/02zsn  Female speech, woman speaking\n",
      "3      3   /m/0ytgt     Child speech, kid speaking\n",
      "4      4  /m/01h8n0                   Conversation\n",
      "-----------------\n",
      "     index         mid        display_name\n",
      "137    137    /m/04rlf               Music\n",
      "138    138    /m/04szw  Musical instrument\n",
      "152    152  /m/05148p4  Keyboard (musical)\n",
      "216    216    /m/064t9           Pop music\n",
      "217    217  /m/0glt670       Hip hop music\n"
     ]
    }
   ],
   "source": [
    "print(class_labels.head())\n",
    "print('-----------------')\n",
    "print(music_class.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_labels (527, 3)\n",
      "music_class (44, 3)\n",
      "-----------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 527 entries, 0 to 526\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   index         527 non-null    int64 \n",
      " 1   mid           527 non-null    object\n",
      " 2   display_name  527 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 12.5+ KB\n",
      "None\n",
      "-----------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 44 entries, 137 to 282\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   index         44 non-null     int64 \n",
      " 1   mid           44 non-null     object\n",
      " 2   display_name  44 non-null     object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.4+ KB\n",
      "None\n",
      "-----------------\n",
      "[137, 138, 152, 216, 217, 219, 227, 230, 233, 234, 237, 239, 240, 245, 246, 247, 248, 249, 252, 253, 254, 256, 258, 259, 260, 261, 262, 264, 265, 267, 268, 269, 270, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282]\n"
     ]
    }
   ],
   "source": [
    "print('class_labels', class_labels.shape)\n",
    "print('music_class', music_class.shape)\n",
    "print('-----------------')\n",
    "print(class_labels.info())\n",
    "print('-----------------')\n",
    "print(music_class.info())\n",
    "\n",
    "print('-----------------')\n",
    "print(music_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100th file ...\n",
      "Processing 200th file ...\n",
      "Processing 300th file ...\n",
      "Processing 400th file ...\n",
      "Processing 500th file ...\n",
      "Processing 600th file ...\n",
      "Processing 700th file ...\n",
      "Processing 800th file ...\n",
      "Processing 900th file ...\n",
      "Processing 1000th file ...\n",
      "Processing 1100th file ...\n",
      "Processing 1200th file ...\n",
      "Processing 1300th file ...\n",
      "Processing 1400th file ...\n",
      "Processing 1500th file ...\n",
      "Processing 1600th file ...\n",
      "Processing 1700th file ...\n",
      "Processing 1800th file ...\n",
      "Processing 1900th file ...\n",
      "Processing 2000th file ...\n"
     ]
    }
   ],
   "source": [
    "audios = []\n",
    "counter = 0\n",
    "NUM_SECONDS = 10\n",
    "\n",
    "for raw_record in raw_dataset:\n",
    "    example = tf.train.SequenceExample()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "    \n",
    "    # Audio Meta data\n",
    "    audio_labels = example.context.feature['labels'].int64_list.value\n",
    "    start_time = example.context.feature['start_time_seconds'].float_list.value\n",
    "    end_time = example.context.feature['end_time_seconds'].float_list.value\n",
    "    video_id = example.context.feature['video_id'].bytes_list.value\n",
    "    \n",
    "    if not (set(music_labels) & set(audio_labels)):\n",
    "        continue\n",
    "\n",
    "    # Audio Feature\n",
    "    feature_list = example.feature_lists.feature_list['audio_embedding'].feature\n",
    "    final_features = [list(feature.bytes_list.value[0]) for feature in feature_list]\n",
    "    audio_embedding = [item for sublist in final_features[:NUM_SECONDS] for item in sublist]\n",
    "    \n",
    "    if len(final_features) < NUM_SECONDS:\n",
    "        continue\n",
    "    \n",
    "    audio = {\n",
    "        'label': audio_labels,\n",
    "        'video_id': video_id[0],\n",
    "        'start_time': start_time[0],\n",
    "        'end_time': end_time[0],\n",
    "        'data': audio_embedding\n",
    "    }\n",
    "    \n",
    "    audios.append(audio)\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print(f\"Processing {counter}th file ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('music_set.json', 'w') as file:\n",
    "    str_audio = repr(audios)\n",
    "    json.dump(str_audio, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 255, 0, 255, 147, 255, 12, 255, 0, 0],\n",
       " [166, 73, 135, 117, 139, 31, 187, 200, 190, 99],\n",
       " [71, 24, 175, 143, 68, 126, 84, 118, 78, 157],\n",
       " [208, 255, 255, 68, 8, 145, 134, 220, 50, 205]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[audio['data'][:10] for audio in audios[:4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "How to read from `tfrecord` files: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/tfrecord.ipynb#scrollTo=nsEAACHcnm3f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
